{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import emcee\n",
    "import corner\n",
    "import scipy.stats\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "from fit_just_early_lc import prep_light_curve, multifcqfid_lnlike_big_unc, multifcqfid_lnprior_big_unc, multifcqfid_lnposterior_big_unc, lnlike_big_unc\n",
    "\n",
    "from multiprocessing import Pool\n",
    "import time\n",
    "\n",
    "from corner_hack import corner_hack\n",
    "from light_curve_plot import f_t, plot_both_filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_path = \"../../forced_lightcurves/sample_lc_v2/\"\n",
    "salt_df = pd.read_csv(info_path + \"../../Nobs_cut_salt2_spec_subtype_pec.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure the Deviance Information Criterion\n",
    "\n",
    "$$DIC = 2 \\bar{D(\\theta)} - D(\\bar{\\theta})$$\n",
    "\n",
    "where, $D(\\theta) = -2 \\log P(x|\\theta)$.\n",
    "\n",
    "Thus, we need to calculate the mean posterior parameters, AND, the mean likelihood for the posterior parameters. This requires the `multifcqfid_lnlike_big_unc` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "thin_by = 100\n",
    "rel_flux_cutoff = 0.4\n",
    "\n",
    "sn = 'ZTF18abauprj'\n",
    "\n",
    "h5_file = info_path + 'big_unc/{}_emcee_40_varchange.h5'.format(sn)\n",
    "reader = emcee.backends.HDFBackend(h5_file)\n",
    "nsteps = thin_by*np.shape(reader.get_chain())[0]\n",
    "tau = reader.get_autocorr_time(tol=0)\n",
    "burnin = int(5*np.max(tau))\n",
    "samples = reader.get_chain(discard=burnin, thin=np.max([int(np.max(tau)), 1]), flat=True)\n",
    "lnpost = reader.get_log_prob(discard=burnin, thin=np.max([int(np.max(tau)), 1]), flat=True)\n",
    "\n",
    "\n",
    "t_max = float(salt_df['t0_g_adopted'][salt_df['name'] == sn].values)\n",
    "z = float(salt_df['z_adopt'][salt_df['name'] == sn].values)\n",
    "g_max = float(salt_df['fratio_gmax_2adam'][salt_df['name'] == sn].values)\n",
    "r_max = float(salt_df['fratio_rmax_2adam'][salt_df['name'] == sn].values)\n",
    "\n",
    "t_data, f_data, f_unc_data, fcqfid_data = prep_light_curve(info_path+\"{}_force_phot.h5\".format(sn),\n",
    "                                                                     t_max=t_max, \n",
    "                                                                     z=z,\n",
    "                                                                     g_max=g_max,\n",
    "                                                                     r_max=r_max,\n",
    "                                                                     rel_flux_cutoff=rel_flux_cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_samples = np.zeros(len(samples))\n",
    "\n",
    "for samp_num, sample in enumerate(samples):\n",
    "    loglike_samples[samp_num] = multifcqfid_lnlike_big_unc(sample, f_data, t_data, f_unc_data, fcqfid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhat = -2*multifcqfid_lnlike_big_unc(np.mean(samples, axis=0), f_data, t_data, f_unc_data, fcqfid_data)\n",
    "\n",
    "dbar = -2*np.mean(loglike_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-359.9673406752178\n"
     ]
    }
   ],
   "source": [
    "dic = 2*dbar - dhat\n",
    "print(dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about for the $t^2$ model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = info_path + 'big_unc/{}_emcee_40_tsquared.h5'.format(sn)\n",
    "reader = emcee.backends.HDFBackend(h5_file)\n",
    "nsteps = thin_by*np.shape(reader.get_chain())[0]\n",
    "tau = reader.get_autocorr_time(tol=0)\n",
    "burnin = int(5*np.max(tau))\n",
    "samples_tsquared = reader.get_chain(discard=burnin, thin=np.max([int(np.max(tau)), 1]), flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglike_samples_tsquared = np.zeros(len(samples))\n",
    "\n",
    "for samp_num, sample in enumerate(samples_tsquared):\n",
    "    loglike_samples_tsquared[samp_num] = multifcqfid_lnlike_big_unc(sample, f_data, t_data, f_unc_data, fcqfid_data, \n",
    "                                                                    prior='delta2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhat = -2*multifcqfid_lnlike_big_unc(np.mean(samples_tsquared, axis=0), f_data, t_data, f_unc_data, fcqfid_data, \n",
    "                                     prior='delta2')\n",
    "\n",
    "dbar = np.mean(-2*loglike_samples_tsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-311.7311584562079\n"
     ]
    }
   ],
   "source": [
    "dic_tsquared = 2*dbar_tsquared - dhat_tsquared\n",
    "print(dic_tsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over all SNe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:490: RuntimeWarning: divide by zero encountered in power\n",
      "  weights=f_zp_unc_tonight[g_tonight]**(-2))\n",
      "/Users/adamamiller/miniconda3/envs/emcee3/lib/python3.7/site-packages/numpy/lib/function_base.py:388: RuntimeWarning: invalid value encountered in multiply\n",
      "  avg = np.multiply(a, wgt, dtype=result_dtype).sum(axis)/scl\n",
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:493: RuntimeWarning: divide by zero encountered in power\n",
      "  weights=f_zp_unc_tonight[~g_tonight]**(-2))\n",
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:495: RuntimeWarning: invalid value encountered in greater\n",
      "  cutoff_g = np.where((mean_rf < 0) & (mean_g > 0) &\n",
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:496: RuntimeWarning: invalid value encountered in less\n",
      "  (mean_g < rel_flux_cutoff))\n",
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:499: RuntimeWarning: invalid value encountered in greater\n",
      "  cutoff_r = np.where((mean_rf < 0) & (mean_r > 0) &\n",
      "/Users/adamamiller/astronomy/ZTF/early_Ia/2018/ztf_early_Ia_2018/playground/fit_just_early_lc.py:500: RuntimeWarning: invalid value encountered in less\n",
      "  (mean_r < rel_flux_cutoff))\n"
     ]
    }
   ],
   "source": [
    "dic_uniformative_arr = np.zeros(len(salt_df))\n",
    "dic_tsquared_arr = np.zeros(len(salt_df))\n",
    "\n",
    "def get_dic(sn):\n",
    "\n",
    "#     sn, bw = tup\n",
    "    sn_num = np.where(salt_df.name == sn)[0]\n",
    "    \n",
    "    h5_file = info_path + 'big_unc/{}_emcee_40_varchange.h5'.format(sn)\n",
    "    reader = emcee.backends.HDFBackend(h5_file)\n",
    "    thin_by = 100\n",
    "    nsteps = thin_by*np.shape(reader.get_chain())[0]\n",
    "    tau = reader.get_autocorr_time(tol=0)\n",
    "    burnin = int(5*np.max(tau))\n",
    "    samples = reader.get_chain(discard=burnin, thin=np.max(int(np.max(tau)), 0), flat=True)\n",
    "\n",
    "    rel_flux_cutoff = 0.4\n",
    "    t_max = float(salt_df['t0_g_adopted'][salt_df['name'] == sn].values)\n",
    "    z = float(salt_df['z_adopt'][salt_df['name'] == sn].values)\n",
    "    g_max = float(salt_df['fratio_gmax_2adam'][salt_df['name'] == sn].values)\n",
    "    r_max = float(salt_df['fratio_rmax_2adam'][salt_df['name'] == sn].values)\n",
    "\n",
    "    t_data, f_data, f_unc_data, fcqfid_data = prep_light_curve(info_path+\"{}_force_phot.h5\".format(sn),\n",
    "                                                                         t_max=t_max, \n",
    "                                                                         z=z,\n",
    "                                                                         g_max=g_max,\n",
    "                                                                         r_max=r_max,\n",
    "                                                                         rel_flux_cutoff=rel_flux_cutoff)\n",
    "\n",
    "    loglike_samples = np.zeros(len(samples))\n",
    "\n",
    "    for samp_num, sample in enumerate(samples):\n",
    "        loglike_samples[samp_num] = multifcqfid_lnlike_big_unc(sample, f_data, t_data, f_unc_data, fcqfid_data)\n",
    "    \n",
    "    dhat = -2*multifcqfid_lnlike_big_unc(np.mean(samples, axis=0), f_data, t_data, f_unc_data, fcqfid_data)\n",
    "    dbar = -2*np.mean(loglike_samples)\n",
    "    dic = 2*dbar - dhat\n",
    "    \n",
    "    h5_file = info_path + 'big_unc/{}_emcee_40_tsquared.h5'.format(sn)\n",
    "    reader = emcee.backends.HDFBackend(h5_file)\n",
    "    nsteps = thin_by*np.shape(reader.get_chain())[0]\n",
    "    tau = reader.get_autocorr_time(tol=0)\n",
    "    burnin = int(5*np.max(tau))\n",
    "    samples_tsquared = reader.get_chain(discard=burnin, thin=np.max([int(np.max(tau)), 1]), flat=True)\n",
    "    \n",
    "    loglike_samples_tsquared = np.zeros(len(samples_tsquared))\n",
    "\n",
    "    for samp_num, sample in enumerate(samples_tsquared):\n",
    "        loglike_samples_tsquared[samp_num] = multifcqfid_lnlike_big_unc(sample, f_data, t_data, f_unc_data, fcqfid_data, \n",
    "                                                                        prior='delta2')\n",
    "\n",
    "    dhat_tsquared = -2*multifcqfid_lnlike_big_unc(np.mean(samples_tsquared, axis=0), f_data, t_data, f_unc_data, fcqfid_data, \n",
    "                                     prior='delta2')\n",
    "\n",
    "    dbar_tsquared = np.mean(-2*loglike_samples_tsquared)\n",
    "    dic_tsquared = 2*dbar_tsquared - dhat_tsquared\n",
    "\n",
    "    dic_uniformative_arr[sn_num] = dic\n",
    "    dic_tsquared_arr[sn_num] = dic_tsquared\n",
    "    \n",
    "    return (dic, dic_tsquared)\n",
    "\n",
    "pool = Pool()\n",
    "\n",
    "dic_res = pool.map(get_dic, salt_df.name.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2391.37094383815, 2385.5704184161373),\n",
       " (2282.044274500203, 2284.5527852241644),\n",
       " (2096.2180971099406, 2087.6788427537213),\n",
       " (336.36228278976444, 334.976637042548),\n",
       " (1078.5785920779106, 1080.3530304886694),\n",
       " (387.02084208438134, 423.51141844478434),\n",
       " (697.6830174330751, 727.245491474233),\n",
       " (649.065605342614, 656.1243182525432),\n",
       " (311.625077148738, 322.23017372686843),\n",
       " (1078.3051159124343, 831.613790969587),\n",
       " (-2479.8573355069384, -330.08225263390045),\n",
       " (759.2004825329516, 761.4699438968629),\n",
       " (568.9416539055276, 568.8121356086867),\n",
       " (705.7979210783728, 703.7007665305946),\n",
       " (-43.918765940944496, -2.9922319751385444),\n",
       " (1092.6726041258212, 1091.6150688359426),\n",
       " (415.83446988984724, 417.09988044083303),\n",
       " (-24.884973075872608, 427.16673735792006),\n",
       " (644.0142240870101, 656.2194238015306),\n",
       " (-52.47501489751147, 118.60717679127586),\n",
       " (689.7124427026056, 689.0301266393567),\n",
       " (900.3281533688225, 904.004077327386),\n",
       " (561.6535632403404, 573.8158556999831),\n",
       " (587.9837888493776, 596.2814124061962),\n",
       " (1651.370184183163, 1649.7308693434138),\n",
       " (695.8335268902192, 696.9153866869588),\n",
       " (362.5055988032152, 359.94097629435663),\n",
       " (1831.8053309602424, 1824.7344955881345),\n",
       " (709.5294598958923, 705.7756653164158),\n",
       " (244.16581995576624, 248.6849941989562),\n",
       " (474.3895038266203, 478.20071202579555),\n",
       " (1024.8376022312023, 1020.0478930228801),\n",
       " (665.8538939179014, 660.1853216583733),\n",
       " (271.4697908073721, 275.33539730963344),\n",
       " (1121.259371155982, 1119.1860736182864),\n",
       " (1252.73073972953, 1252.1612162607978),\n",
       " (941.6608524743993, 949.2882189333761),\n",
       " (527.2781389133378, 536.017722314346),\n",
       " (1003.1570567189963, 1005.2589654220942),\n",
       " (729.8119071177052, 729.006495201416),\n",
       " (665.3917290322017, 674.2047109320501),\n",
       " (1771.2443248135505, 1768.4536777379344),\n",
       " (175.58767781859518, 173.82231703049888),\n",
       " (794.5567763044346, 796.8587536270168),\n",
       " (1149.4067786010032, 1146.8176633887201),\n",
       " (625.282040925144, 632.3799583662828),\n",
       " (1480.6859818486769, 1476.468228106568),\n",
       " (-359.9673406752178, -311.7311584562079),\n",
       " (801.0883022229875, 801.5806710780514),\n",
       " (2279.3164773339167, 2278.1326469050364),\n",
       " (167.94664981797712, 249.0550753553653),\n",
       " (453.0475627226019, 447.336784026205),\n",
       " (-71.62034047806289, 24.138520454848774),\n",
       " (1320.6821242130027, 1329.8287633765283),\n",
       " (481.66584723250264, 480.30140869312766),\n",
       " (1011.1306866841933, 1009.858943497658),\n",
       " (2340.646677207682, 2358.714955099608),\n",
       " (110.57724745036907, 114.12847445312804),\n",
       " (1257.8053969417997, 1256.730084794771),\n",
       " (998.0395481940158, 993.0537219051046),\n",
       " (1030.5249276378281, 1029.9041483539836),\n",
       " (1973.7386598655974, 1973.8455157485714),\n",
       " (357.3243631352843, 353.1917301889333),\n",
       " (1264.0651628551013, 1260.1337500313816),\n",
       " (1965.1579366845851, 1962.988610541632),\n",
       " (1085.6600737877677, 1081.8913432533855),\n",
       " (1070.049957059157, 1065.892550996205),\n",
       " (1644.0443087888918, 1642.2300291228778),\n",
       " (129.70727770278376, 128.0512236592434),\n",
       " (3720.174135995098, 3715.0741367016826),\n",
       " (382.506444345703, 379.0910028376695),\n",
       " (1250.1322812183826, 1251.4073800225437),\n",
       " (1226.6612505522412, 1225.4975494777218),\n",
       " (2457.797181099133, 2456.434257517417),\n",
       " (1876.8051516642056, 1885.3431529401983),\n",
       " (2811.86622625982, 2805.0834369971963),\n",
       " (81.24483710881714, 150.79343394327248),\n",
       " (1520.7647414952116, 1520.8318679426443),\n",
       " (693.5456685773543, 692.4871057517998),\n",
       " (492.25238162615716, 516.6431145292083),\n",
       " (1410.727608640383, 1410.4139815596166),\n",
       " (1725.6095435693362, 1723.5067045598928),\n",
       " (2650.2295071055696, 2649.181364399291),\n",
       " (2211.4869210043576, 2216.8961441658294),\n",
       " (1933.6360234211431, 1931.2913513351818),\n",
       " (1093.6982172742028, 1089.2707394705344),\n",
       " (2552.8661753009055, 2548.6291234304254),\n",
       " (721.3810776181293, 729.3096327792255),\n",
       " (857.7631210906917, 857.9470241188353),\n",
       " (905.1256160674304, 904.2021563693951),\n",
       " (136.21597489041835, 147.7474682603619),\n",
       " (1704.342333084216, 1701.377505618701),\n",
       " (1313.3509874993415, 1310.7125336912977),\n",
       " (1718.1420540921777, 1713.5384252064314),\n",
       " (2468.271164800374, 2464.5943671954756),\n",
       " (1775.7090999874022, 1776.9149360800275),\n",
       " (520.5589794282987, -14203.849443286716),\n",
       " (3329.0056056191743, 3322.7015763924655),\n",
       " (397.0695374007357, 398.0920900013173),\n",
       " (2399.2651397731406, 2398.059168021014),\n",
       " (2101.5202887668456, 2098.536957651703),\n",
       " (4360.439605208829, 4367.756888575623),\n",
       " (3898.1303458092407, 3899.808490412959),\n",
       " (1655.3984007116246, 1654.5975815021613),\n",
       " (2826.1957417858457, 2821.574009165889),\n",
       " (2295.6029463181385, 2295.478529807726),\n",
       " (2937.7710376970754, 2948.182929089749),\n",
       " (4381.987298408372, 4376.600647165276),\n",
       " (2682.284371491098, 2677.2847207295576),\n",
       " (2134.180876298076, 2131.741488229129),\n",
       " (1922.703152655378, 1924.4031174349943),\n",
       " (5251.974267408332, 5247.224914838506),\n",
       " (2103.2028193831115, 2099.009063111307),\n",
       " (2052.8677786287367, 2048.3427248720377),\n",
       " (1113.4298108239573, 1110.252715364439),\n",
       " (3634.624831195146, 3631.255414483726),\n",
       " (2587.3391116986145, 2583.6771873196044),\n",
       " (1126.618536111032, 1162.3267044807178),\n",
       " (1634.8139062485511, 1631.2198707101352),\n",
       " (-35.6690560191152, 15.21556306230897),\n",
       " (2343.3457795869035, 2334.9790665926175),\n",
       " (1686.532556676684, 1686.3347636711712),\n",
       " (3321.9794719557726, 3323.078298864052),\n",
       " (1797.008651579615, 1793.0408612121682),\n",
       " (4064.731169871171, 4061.1224950622654),\n",
       " (2096.8423900217717, 2094.0098657582325),\n",
       " (3666.453331137673, 3661.268077644425)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_uniformative_arr = np.array(dic_res)[:,0]\n",
    "dic_tsquared_arr = np.array(dic_res)[:,1]\n",
    "\n",
    "\n",
    "dic_df = pd.DataFrame(salt_df.name.values, columns=['ztf_name'])\n",
    "dic_df['dic_uninformative'] = dic_uniformative_arr\n",
    "dic_df['dic_delta2'] = dic_tsquared_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_evidence = np.array(['very strong']*len(salt_df))\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) <= 1))] = 'negative'\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) > 1) & \n",
    "                      (np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) <= 3))] = 'weak'\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) > 3) & \n",
    "                      (np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) <= 10))] = 'substantial'\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) > 10) & \n",
    "                      (np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) <= 30))] = 'strong'\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) > 30) & \n",
    "                      (np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) <= 100))] = 'very strong'\n",
    "dic_evidence[np.where((np.exp((dic_tsquared_arr - dic_uniformative_arr)/2) > 100))] = 'decisive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['negative', 'substantial', 'negative', 'negative', 'weak',\n",
       "       'decisive', 'decisive', 'very strong', 'decisive', 'negative',\n",
       "       'decisive', 'substantial', 'negative', 'negative', 'decisive',\n",
       "       'negative', 'weak', 'decisive', 'decisive', 'decisive', 'negative',\n",
       "       'substantial', 'decisive', 'very strong', 'negative', 'weak',\n",
       "       'negative', 'negative', 'negative', 'substantial', 'substantial',\n",
       "       'negative', 'negative', 'substantial', 'negative', 'negative',\n",
       "       'very strong', 'very strong', 'weak', 'negative', 'very strong',\n",
       "       'negative', 'negative', 'substantial', 'negative', 'very strong',\n",
       "       'negative', 'decisive', 'weak', 'negative', 'decisive', 'negative',\n",
       "       'decisive', 'very strong', 'negative', 'negative', 'decisive',\n",
       "       'substantial', 'negative', 'negative', 'negative', 'weak',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'negative', 'negative', 'negative', 'weak', 'negative',\n",
       "       'negative', 'very strong', 'negative', 'decisive', 'weak',\n",
       "       'negative', 'decisive', 'negative', 'negative', 'negative',\n",
       "       'strong', 'negative', 'negative', 'negative', 'very strong',\n",
       "       'weak', 'negative', 'decisive', 'negative', 'negative', 'negative',\n",
       "       'negative', 'weak', 'negative', 'negative', 'weak', 'negative',\n",
       "       'negative', 'very strong', 'weak', 'negative', 'negative',\n",
       "       'negative', 'decisive', 'negative', 'negative', 'negative', 'weak',\n",
       "       'negative', 'negative', 'negative', 'negative', 'negative',\n",
       "       'negative', 'decisive', 'negative', 'decisive', 'negative',\n",
       "       'negative', 'weak', 'negative', 'negative', 'negative', 'negative'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['decisive', 'negative', 'strong', 'substantial', 'very strong',\n",
       "        'weak'], dtype='<U11'), array([19, 75,  1,  8, 10, 14]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(dic_evidence, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_df['dic_evidence'] = dic_evidence\n",
    "dic_df.to_csv('dic_results.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
